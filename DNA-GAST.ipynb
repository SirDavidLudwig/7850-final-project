{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b93464dc-d77a-4ce1-9d95-4271be5950a2",
   "metadata": {},
   "source": [
    "# DNA-GAST\n",
    "\n",
    "This notebook explores the utilization of the GAST model for high-dimensional set elements in the form of pre-trained embeddings. The original DNA samples have been encoded and stored into *shelve* files located within the `./datasets/dna` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003962f6-24f9-4f14-9a62-9b09eadb8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b2f56c-3197-4adb-a0ee-8248ec31b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_addons as tfa\n",
    "import time\n",
    "import shelve\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import settransformer as sf\n",
    "\n",
    "import common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f820c5e-0b90-4314-baa1-0c57ff936957",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0739d61-c54d-47c6-ad44-117ef95d3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = common.strategy(\"gpu:0\")\n",
    "# strategy = common.strategy(multi_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea5f7d1-42be-4fbb-8cff-fb195cfd254a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the original implementation of multihead attention\n",
    "# from the official Pytorch implementation of set transformer\n",
    "sf.config(\"use_keras_mha\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfe6941-490b-4595-8227-ee1159765f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "KMERS = 3\n",
    "SEQUENCE_LENGTH = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f318733-b5ce-46dc-9901-d17f44bfaea4",
   "metadata": {},
   "source": [
    "## Pre-trained Embedding Model\n",
    "\n",
    "This model is a pre-trained embedding model designed for 3-mer 128-dim embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f384dc4a-bddc-4ab7-b439-8e1f7147848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50)]              0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 128)               246336    \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 50, 125)           247933    \n",
      "=================================================================\n",
      "Total params: 494,269\n",
      "Trainable params: 494,269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_length = int(SEQUENCE_LENGTH / KMERS)\n",
    "num_tokens = 5**KMERS\n",
    "embed_dim = 32\n",
    "latent_dim = 128\n",
    "num_heads = 8\n",
    "enc_stack = 1\n",
    "dec_stack = 1\n",
    "\n",
    "with strategy.scope():\n",
    "    # Encoder\n",
    "    y = x = keras.layers.Input((sequence_length,))\n",
    "    y = keras.layers.Embedding(input_dim=num_tokens, output_dim=embed_dim)(y)\n",
    "    y = common.FixedPositionEmbedding(length=sequence_length, embed_dim=embed_dim)(y)\n",
    "    for _ in range(enc_stack):\n",
    "        y = common.TransformerBlock(embed_dim, num_heads, ff_dim=embed_dim)(y)\n",
    "    y = keras.layers.Flatten()(y)\n",
    "    y = keras.layers.Dense(latent_dim)(y)\n",
    "    encoder = keras.Model(x, y)\n",
    "\n",
    "    # Decoder\n",
    "    y = x = keras.layers.Input((encoder.output.shape[1:]))\n",
    "    y = keras.layers.Dense(sequence_length*embed_dim)(y)\n",
    "    y = keras.layers.Reshape((-1, embed_dim))(y)\n",
    "    y = embed = common.FixedPositionEmbedding(length=sequence_length, embed_dim=embed_dim)(y)\n",
    "    for _ in range(dec_stack):\n",
    "        y = common.TransformerBlock(embed_dim, num_heads, ff_dim=embed_dim)(y)\n",
    "        y = keras.layers.Add()((embed, y))\n",
    "    y = keras.layers.Dense(num_tokens, activation=\"softmax\")(y)\n",
    "    decoder = keras.Model(x, y)\n",
    "\n",
    "    # Coupled model\n",
    "    y = x = keras.layers.Input(encoder.input.shape[1:])\n",
    "    y = encoder(y)\n",
    "    y = decoder(y)\n",
    "    embed_model = keras.Model(x, y)\n",
    "    embed_model.encoder = encoder\n",
    "    embed_model.decoder = decoder\n",
    "    embed_model.compile(\n",
    "        keras.optimizers.Nadam(1e-3),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "    embed_model.summary()\n",
    "    \n",
    "    embed_model.load_weights(\"./models/embedding.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0c8f7-0462-4323-ad2c-89bcd2380a8e",
   "metadata": {},
   "source": [
    "## Sample Embedding Generation\n",
    "\n",
    "The following code iterates over all available processed sample files and predicts learned embeddings of augmented DNA samples to a corresponding output file. This process may take a while on the first run as it needs to create the sample stores. Existing stores will be skipped to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93b658d4-7629-4ec4-ae66-34054bc1eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/dna/embedded\"):\n",
    "    os.mkdir(\"./datasets/dna/embedded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a87e56f7-7b12-48db-86bc-40fe07991987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(sample, sequence_length):\n",
    "    offset = np.random.randint(sample.shape[0] - sequence_length + 1)\n",
    "    return sample[offset:sequence_length+offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2b5741-a369-4f84-93a4-4194640c8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_generator(store, batch_size):\n",
    "    num_samples = store[\"length\"]\n",
    "    kmer_sequence_length = int(SEQUENCE_LENGTH / KMERS)\n",
    "    kmer_powers = np.full(KMERS, 5)**np.arange(KMERS - 1, -1, -1)\n",
    "\n",
    "    for batch_index in range(0, num_samples, batch_size):\n",
    "        num_samples_in_batch = min(num_samples - batch_index, batch_size)\n",
    "        samples = np.empty(shape=(num_samples_in_batch, SEQUENCE_LENGTH), dtype=np.int32)\n",
    "        for i in range(0, num_samples_in_batch):\n",
    "            samples[i] = augment(store[str(batch_index + i)][0], SEQUENCE_LENGTH)\n",
    "        batch = np.sum(samples.reshape((num_samples_in_batch, -1, KMERS)) * kmer_powers, axis=2)\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cef892d8-76a1-49fc-8b57-9ff113cbd6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spring_2016-04-22',\n",
       " 'spring_2019-05-14',\n",
       " 'fall_2017-10-13',\n",
       " 'spring_2020-05-11',\n",
       " 'fall_2016-10-07',\n",
       " 'spring_2017-05-02',\n",
       " 'spring_2018-04-23']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f[:-3] for f in os.listdir(\"./datasets/dna\") if f.endswith(\".db\")]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91851c78-e4d6-4afa-b07d-86b1d558dc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 0.00044274330139160156 seconds.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "with strategy.scope():\n",
    "    with common.Benchmark() as progress:\n",
    "        for file in files:\n",
    "            dest = f\"./datasets/dna/embedded/3mer_128_{file}\"\n",
    "            if os.path.exists(dest + \".db\"):\n",
    "                continue\n",
    "            in_store = shelve.open(f\"./datasets/dna/{file}\")\n",
    "            out_store = shelve.open(dest)\n",
    "            num_samples = in_store[\"length\"]\n",
    "            num_batches = int(np.ceil(num_samples / batch_size))\n",
    "            for i, batch in enumerate(sample_generator(in_store, batch_size)):\n",
    "                for j, sample in enumerate(encoder(batch)):\n",
    "                    out_store[str(batch_size*i+j)] = sample\n",
    "                print(f\"\\rBatch: {i+1}/{num_batches}\", end=\"\")\n",
    "            print()\n",
    "            out_store[\"length\"] = num_samples\n",
    "            out_store.close()\n",
    "            in_store.close()\n",
    "            progress.checkpoint(f\"File: {file} completed, {num_samples:,} processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b764d8f-0bd9-4721-bef2-cce5fe9fc058",
   "metadata": {},
   "source": [
    "## DNA Dataset\n",
    "\n",
    "Load the DNA samples into a sample generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52935bf-6cfc-4ce3-8142-5d50a2349f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"./datasets/dna\")\n",
    "files = [f\"./datasets/dna/{f[:-3]}\" for f in files if f.endswith(\".db\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717d8fd8-9656-484a-ba2d-0d6b10a6c4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./datasets/dna/spring_2016-04-22',\n",
       " './datasets/dna/spring_2019-05-14',\n",
       " './datasets/dna/fall_2017-10-13',\n",
       " './datasets/dna/spring_2020-05-11',\n",
       " './datasets/dna/fall_2016-10-07',\n",
       " './datasets/dna/spring_2017-05-02',\n",
       " './datasets/dna/spring_2018-04-23']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29302239-226e-4bd6-b2b2-4ef2c494f74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_PER_REPLICA = 32\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "KMERS = 3\n",
    "SEQUENCE_LENGTH = 150\n",
    "SUBSAMPLE_SIZE = 1000\n",
    "BUFFER_SIZE = 20\n",
    "NUM_WORKERS = 4\n",
    "KMER_SEQUENCE_LENGTH = int(SEQUENCE_LENGTH / KMERS)\n",
    "DNA_EMBED_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b51b5cc-e664-4d1b-ae19-9b362d88dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_data_generator = common.MultiprocessDnaSampler(\n",
    "    files=files,\n",
    "    kmers=KMERS,\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    batch_size=GLOBAL_BATCH_SIZE,\n",
    "    subsample_size=SUBSAMPLE_SIZE,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    "    num_workers=NUM_WORKERS)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    dna_data_generator.generator,\n",
    "    output_types=(tf.int32),\n",
    "    output_shapes=(\n",
    "        tf.TensorShape([GLOBAL_BATCH_SIZE, SUBSAMPLE_SIZE, KMER_SEQUENCE_LENGTH])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb20d53a-6871-4344-aa08-5d93c1944641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abd1030b-4fef-4ff8-ae62-ceaa41e98b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_data_generator.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7e7124-0efa-4032-9c1d-a123de22bf17",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e5065e5-b63e-4a2a-86d2-2376fd99e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 64\n",
    "EMBED_DIM = 192\n",
    "LATENT_DIM = EMBED_DIM*4\n",
    "NUM_HEADS = 12\n",
    "NUM_ANCHORS = 48\n",
    "MAX_SET_SIZE = SUBSAMPLE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd67242-fba7-44c2-bfdf-838ecf7c6e37",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d7919c-dcdb-4a4f-a73b-1ed31b449727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 64)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sample_set (SampleSet)          (None, None, 192)    384000      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization (Spectra (None, 64)           4224        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conditioned_isab (ConditionedIS (None, None, 192)    1502848     sample_set[0][0]                 \n",
      "                                                                 spectral_normalization[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 192)    0           conditioned_isab[0][0]           \n",
      "                                                                 sample_set[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conditioned_isab_1 (Conditioned (None, None, 192)    1502848     add_1[0][0]                      \n",
      "                                                                 spectral_normalization[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 192)    0           conditioned_isab_1[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conditioned_isab_2 (Conditioned (None, None, 192)    1502848     add_2[0][0]                      \n",
      "                                                                 spectral_normalization[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, 192)    0           conditioned_isab_2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conditioned_isab_3 (Conditioned (None, None, 192)    1502848     add_3[0][0]                      \n",
      "                                                                 spectral_normalization[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization_5 (Spect (None, None, 128)    24704       conditioned_isab_3[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 6,424,320\n",
      "Trainable params: 6,387,264\n",
      "Non-trainable params: 37,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    noise = keras.layers.Input((NOISE_DIM,))\n",
    "    cardinality = keras.layers.Input((1,), dtype=tf.int32)\n",
    "    \n",
    "    condition = tfa.layers.SpectralNormalization(keras.layers.Dense(NOISE_DIM))(noise)\n",
    "    \n",
    "    y1 = y = common.SampleSet(MAX_SET_SIZE, EMBED_DIM)(cardinality)\n",
    "    \n",
    "    # Condition the set\n",
    "    y1 = common.ConditionedISAB(embed_dim=EMBED_DIM, dim_cond=NOISE_DIM, num_heads=NUM_HEADS, num_anchors=NUM_ANCHORS)((y, condition))\n",
    "    y = keras.layers.Add()((y1, y))\n",
    "    y1 = common.ConditionedISAB(embed_dim=EMBED_DIM, dim_cond=NOISE_DIM, num_heads=NUM_HEADS, num_anchors=NUM_ANCHORS)((y, condition))\n",
    "    y = keras.layers.Add()((y1, y))\n",
    "    y1 = common.ConditionedISAB(embed_dim=EMBED_DIM, dim_cond=NOISE_DIM, num_heads=NUM_HEADS, num_anchors=NUM_ANCHORS)((y, condition))\n",
    "    y = keras.layers.Add()((y1, y))\n",
    "    y = common.ConditionedISAB(embed_dim=EMBED_DIM, dim_cond=NOISE_DIM, num_heads=NUM_HEADS, num_anchors=NUM_ANCHORS)((y, condition))\n",
    "    \n",
    "    y = tfa.layers.SpectralNormalization(keras.layers.Dense(DNA_EMBED_DIM, use_bias=False))(y)\n",
    "    generator = keras.Model((noise, cardinality), y)\n",
    "    generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6595e-b082-412d-9800-2957ffe59f9d",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f23b146d-3330-40da-af96-82f9aca59b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, None, 128)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization_6 (Spect (None, None, 192)    24960       input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "induced_set_attention_block (In (None, None, 192)    305664      spectral_normalization_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, 192)    0           spectral_normalization_6[0][0]   \n",
      "                                                                 induced_set_attention_block[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "induced_set_attention_block_1 ( (None, None, 192)    305664      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, 192)    0           add_4[0][0]                      \n",
      "                                                                 induced_set_attention_block_1[0][\n",
      "__________________________________________________________________________________________________\n",
      "induced_set_attention_block_2 ( (None, None, 192)    305664      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, 192)    0           add_5[0][0]                      \n",
      "                                                                 induced_set_attention_block_2[0][\n",
      "__________________________________________________________________________________________________\n",
      "induced_set_encoder (InducedSet (None, 192)          148416      add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "induced_set_encoder_1 (InducedS (None, 192)          148416      add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "induced_set_encoder_2 (InducedS (None, 192)          148416      add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 576)          0           induced_set_encoder[0][0]        \n",
      "                                                                 induced_set_encoder_1[0][0]      \n",
      "                                                                 induced_set_encoder_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "spectral_normalization_7 (Spect (None, 1)            578         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,387,778\n",
      "Trainable params: 1,387,585\n",
      "Non-trainable params: 193\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    y = x = keras.layers.Input((None, DNA_EMBED_DIM))\n",
    "    y1 = y = tfa.layers.SpectralNormalization(keras.layers.Dense(EMBED_DIM))(y)\n",
    "#     e0 = sf.ISE(1, LATENT_DIM, 4)(y)\n",
    "    \n",
    "    enc = []\n",
    "    for i in range(3):\n",
    "        y = sf.ISAB(EMBED_DIM, num_heads=NUM_HEADS, num_induce=NUM_ANCHORS)(y)\n",
    "        y1 = y = keras.layers.Add()((y1, y))\n",
    "        enc.append(sf.ISE(1, EMBED_DIM, NUM_HEADS)(y))\n",
    "\n",
    "    y = keras.layers.Concatenate()(enc)\n",
    "\n",
    "    y = tfa.layers.SpectralNormalization(keras.layers.Dense(1))(y)\n",
    "\n",
    "    discriminator = keras.Model(x, y)\n",
    "    discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f52677-b401-4cff-80c8-46d5b82b4ebb",
   "metadata": {},
   "source": [
    "### Coupled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "239f97bd-fb72-4d32-b36d-b26d433adb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    x1 = keras.layers.Input(generator.input_shape[0][1:])\n",
    "    x2 = keras.layers.Input(generator.input_shape[1][1:])\n",
    "    y = generator((x1, x2))\n",
    "    y = discriminator(y)\n",
    "    model = keras.Model((x1, x2), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba31a79-0656-407a-bb1c-63d0b1321b76",
   "metadata": {},
   "source": [
    "## Loss Functions\n",
    "\n",
    "Note: the original paper uses a version of Hinge loss. This implementation utilizes the basic binary crossentropy loss for the generator and discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b5cdbf2-c269-4563-99d0-779dd06c70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    loss_obj = keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9ea717f-b546-4321-8ed6-b41b420f48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generator_loss(fake_output):\n",
    "#     loss = -tf.reduce_mean(fake_output)\n",
    "#     return loss\n",
    "\n",
    "# def discriminator_loss(real_output, fake_output):\n",
    "#     real_loss = tf.reduce_mean(tf.maximum(1 - real_output, 0))\n",
    "#     fake_loss = tf.reduce_mean(tf.maximum(1 + fake_output, 0))\n",
    "#     loss = real_loss + fake_loss\n",
    "#     return loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    loss = loss_obj(tf.ones_like(fake_output), fake_output)\n",
    "    return tf.nn.compute_average_loss(loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss_obj(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = loss_obj(tf.zeros_like(fake_output), fake_output)\n",
    "    loss = real_loss + fake_loss\n",
    "    return tf.nn.compute_average_loss(loss, global_batch_size=GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd54637-b716-424a-bdd1-04c1a120fbed",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03830825-7dd3-4de3-b88d-fc0a68e7f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    gen_optimizer = keras.optimizers.Adam(1e-4)\n",
    "    disc_optimizer = keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70888686-948b-4aaa-af95-e2fe48abed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(optimizers):\n",
    "    for optimizer in optimizers:\n",
    "        optimizer.learning_rate.assign(optimizer.learning_rate*0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da40c6-64fa-4398-8a26-5a23bb48aa2a",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "It's worth noting that the generator conditions currently randomly samples points regardless of the given noise input. This causes generated preview digits to be inconsistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7b086d5-9873-4317-8cd1-eeddf6726ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(real, k):\n",
    "#     for _ in range(k):\n",
    "    noise = tf.random.normal((BATCH_SIZE_PER_REPLICA, NOISE_DIM))\n",
    "    n = tf.repeat(tf.constant([SUBSAMPLE_SIZE]), tf.shape(noise)[0])\n",
    "    \n",
    "    # Embed the given real sequences\n",
    "    b = tf.reshape(real, (-1, KMER_SEQUENCE_LENGTH))\n",
    "    embedded_real = embed_model.encoder(b)\n",
    "    real = tf.reshape(embedded_real, (-1, SUBSAMPLE_SIZE, DNA_EMBED_DIM))\n",
    "        \n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "        fake = generator((noise, n))\n",
    "        fake_output = discriminator(fake)\n",
    "        real_output = discriminator(real)\n",
    "        \n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        \n",
    "#         disc_loss = tf.reduce_mean(tf.maximum(1 - real_output, 0)) + tf.reduce_mean(tf.maximum(1 + fake_output, 0))\n",
    "#         gen_loss = - tf.reduce_mean(fake_output)\n",
    "    \n",
    "    disc_grads = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    gen_grads = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    \n",
    "    disc_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
    "    gen_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
    "    \n",
    "    return disc_loss, gen_loss\n",
    "\n",
    "@tf.function()\n",
    "def distributed_train_step(batch, k):\n",
    "    losses = strategy.run(train_step, args=(batch, k))\n",
    "    return strategy.reduce(tf.distribute.ReduceOp.MEAN, losses, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca9cd694-9f63-45d5-8c37-9f4b4c55ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to preview during training\n",
    "test_noise = tf.random.normal((5, NOISE_DIM))\n",
    "n = tf.repeat(tf.constant([SUBSAMPLE_SIZE]), tf.shape(test_noise)[0])\n",
    "disc_losses = []\n",
    "gen_losses = []\n",
    "step = 0\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67041c9c-692d-4d06-ad78-b365f28d71d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2211/10000; 0.18s; Generator loss: 3.6106903553009033; Discriminator loss: 0.72981196641922"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "with strategy.scope():\n",
    "    num_steps = 10000\n",
    "    \n",
    "    data_iterator = iter(train_dist_dataset)\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        end_step = step + num_steps\n",
    "        for step in range(step, end_step):\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                test_store = shelve.open(\"./results/dna_gen\")\n",
    "                test_store[str(step)] = generator((test_noise, n))\n",
    "                test_store.close()\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            batch = next(data_iterator)[0]\n",
    "            losses = distributed_train_step(batch, k)\n",
    "            disc_loss = losses[0]\n",
    "            gen_loss = losses[1]\n",
    "            display.clear_output(wait=True)\n",
    "            print(f\"\\rStep: {step}/{end_step}; {time.time() - start:.2}s; Generator loss: {gen_loss/(i+1)}; Discriminator loss: {disc_loss/(i+1)}\", end=\"\")\n",
    "            disc_losses.append(disc_loss / (i+1))\n",
    "            gen_losses.append(gen_loss / (i+1))\n",
    "\n",
    "        #     if epoch % 10 == 0:\n",
    "        #         model.save_weights(f\"gast_epoch_{epoch}.h5\")\n",
    "    except KeyboardInterrupt as e:\n",
    "        test_store.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f27ac3-8360-48c0-a6c0-e105b08cd857",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./models/dnagast.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4614dd53-b79c-47a1-8f68-5b693f8dd980",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "After training, we can evaluate the model by comparing sample similarity using Chamfer distance. The similarity can be visualized using metric multi-dimensional scaling (MDS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90dd5a-f314-40ba-b210-76fa05b65ea4",
   "metadata": {},
   "source": [
    "The following cell implements the Chamfer distance metric in Cython utilizing cityblock distance between points rather than euclidean as Manhattan distance can achieve more meaningful results for higher-dimension elements (https://bib.dbvis.de/uploadedFiles/155.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c74f084-4852-43bf-ba41-a72fc584b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cpdef float chamfer_distance_cython(float[:,:] a, float[:,:] b):\n",
    "    cdef float total_dist = 0.0\n",
    "    cdef float d\n",
    "    cdef float min_d\n",
    "    cdef int i, j, k\n",
    "    cdef int len_a = len(a)\n",
    "    cdef int len_b = len(b)\n",
    "    cdef int point_width = len(a[0])\n",
    "    for i in range(len_a):\n",
    "        min_d = -1\n",
    "        for j in range(len_b):\n",
    "            d = 0.0\n",
    "            for k in range(point_width):\n",
    "                d += abs(b[j][k] - a[i][k])\n",
    "            if d < min_d or min_d == -1.0:\n",
    "                min_d = d\n",
    "        total_dist += min_d\n",
    "    return total_dist / len_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984118be-3ad3-418c-85cc-3aa84e9d1bb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MDS of Embedded Samples\n",
    "\n",
    "This first section computes the Chamfer distances and generates the MDS plot for the landmark samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddb30ba9-440f-41a0-9153-c001ba0ce153",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LANDMARKS_PER_SAMPLE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d91b7e5c-dea0-444a-8d35-6f84436f5806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spring_2016-04-22',\n",
       " 'spring_2019-05-14',\n",
       " 'fall_2017-10-13',\n",
       " 'spring_2020-05-11',\n",
       " 'fall_2016-10-07',\n",
       " 'spring_2017-05-02',\n",
       " 'spring_2018-04-23']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f[:-3] for f in os.listdir(\"./datasets/dna\") if f.endswith(\".db\")]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e0784a8-cca7-480d-af00-f6d0034e7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"./datasets/dna/embedded/3mer_128_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b983f533-5e28-4c86-a212-a4058f5ab26b",
   "metadata": {},
   "source": [
    "### Subsampling\n",
    "\n",
    "This cell loads a number of subsamples from each of the main sample files available. Specifically, this cell subsamples the full sample, taking only 1,000 DNA sequences at random without replacement for each subsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01a2127e-487d-41d8-a096-88468bcfa1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous landmark subsamples loaded\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./results/dna_landmarks.npy\"):\n",
    "    print(\"Previous landmark subsamples loaded\")\n",
    "    samples = np.load(\"./results/dna_landmarks.npy\")\n",
    "    num_samples_per_file = NUM_LANDMARKS_PER_SAMPLE\n",
    "    sample_size = samples.shape[1]\n",
    "    embed_dim = samples.shape[2]\n",
    "    \n",
    "else:\n",
    "    num_samples_per_file = NUM_LANDMARKS_PER_SAMPLE\n",
    "    sample_size = 1000\n",
    "    embed_dim = 128\n",
    "    samples = np.empty((len(files)*num_samples_per_file, sample_size, embed_dim), dtype=np.float32)\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        store = shelve.open(prefix + file)\n",
    "        store_len = store[\"length\"]\n",
    "        for j in range(num_samples_per_file):\n",
    "            for k, index in enumerate(np.random.choice(np.arange(store_len), sample_size, replace=False)):\n",
    "                samples[i*num_samples_per_file+j][k] = store[str(index)]\n",
    "    np.save(\"./results/dna_landmarks.npy\", samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd58253-8749-4212-8041-adb3ea121810",
   "metadata": {},
   "source": [
    "### Subsample Similarity with Chamfer Distance\n",
    "\n",
    "This next cell computes the Chamfer distance between each of the chosen subsamples. If the distances have been computed previously, they will be loaded instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "600fb2d6-11eb-4614-9463-308338f442a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous distances loaded from file\n"
     ]
    }
   ],
   "source": [
    "filename = \"./results/dna_landmark_distances.npy\"\n",
    "if os.path.exists(filename):\n",
    "    distances = np.load(filename)\n",
    "    print(\"Previous distances loaded from file\")\n",
    "    \n",
    "else:\n",
    "    n = len(samples)\n",
    "\n",
    "    distances = np.empty(shape=(n, n))\n",
    "    with strategy.scope():\n",
    "        with common.Benchmark():\n",
    "            for i in range(n):\n",
    "                distances[i][i] = 0.0\n",
    "                for j in range(i+1, n):\n",
    "                    # distances[i][j] = chamfer_distance.evaluate(samples[i], samples[j])\n",
    "                    distances[i][j] = chamfer_distance_cython(samples[i], samples[j])\n",
    "                    distances[j][i] = distances[i][j]\n",
    "                    print(f\"\\rM[{i}][{j}]\", end=\"\")\n",
    "        print()\n",
    "    np.save(filename, distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90353c9-10ff-450b-ae37-684068782689",
   "metadata": {},
   "source": [
    "### Load GAN Subsamples from Shelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd80e421-daea-4452-8468-4e7c6b0de552",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000 # Which step count to sample from\n",
    "store = shelve.open(\"./results/dna_gen\")\n",
    "gen_samples = store[str(steps)]\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3782924-0566-4eca-8fc4-9ed5288866e3",
   "metadata": {},
   "source": [
    "### Compute New Chamfer Distances\n",
    "\n",
    "**Note:** We could speed this process up here by using Nystroem approximations... Not sure how yet though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f799da1-871a-4b98-89b0-ae1804b44f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_distances = np.zeros(np.add(distances.shape, gen_samples.shape[0]))\n",
    "new_distances[:distances.shape[0], :distances.shape[1]] = distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cedbf48b-dfb2-4493-bb99-1e188ff68eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M[73][74]"
     ]
    }
   ],
   "source": [
    "n = len(distances)\n",
    "N = len(new_distances)\n",
    "for i in range(n, N):\n",
    "    new_distances[i][i] = 0.0\n",
    "    for j in range(0, n):\n",
    "        new_distances[i][j] = chamfer_distance_cython(gen_samples[i-n].numpy(), samples[j])\n",
    "        new_distances[j][i] = new_distances[i][j]\n",
    "    for j in range(i+1, N):\n",
    "        new_distances[i][j] = chamfer_distance_cython(gen_samples[i-n].numpy(), gen_samples[j-n].numpy())\n",
    "        new_distances[j][i] = new_distances[i][j]\n",
    "        print(f\"\\rM[{i}][{j}]\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4456ec0d-0f1e-4444-af37-9af694373d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1405.53210449, 1419.32189941, 1425.29492188, 1419.03234863,\n",
       "       1420.88525391, 1391.75866699, 1439.32983398, 1251.3302002 ,\n",
       "       1346.53027344, 1428.57958984, 1469.4473877 , 1450.57592773,\n",
       "       1483.40332031, 1442.38891602, 1437.13952637, 1500.20141602,\n",
       "       1508.11547852, 1494.0480957 , 1481.0501709 , 1433.18127441,\n",
       "       1444.96899414, 1468.66845703, 1449.80627441, 1419.33276367,\n",
       "       1363.19763184, 1455.27844238, 1457.82885742, 1452.71105957,\n",
       "       1484.60632324, 1449.64782715, 1457.9543457 , 1351.34545898,\n",
       "       1452.8347168 , 1303.6237793 , 1480.12280273, 1397.38867188,\n",
       "       1303.6237793 , 1471.0723877 , 1476.92565918, 1462.77685547,\n",
       "       1396.28637695, 1382.8470459 , 1407.41162109, 1426.58581543,\n",
       "       1402.80517578, 1419.97363281, 1398.32397461, 1396.20874023,\n",
       "       1393.22692871, 1399.97717285, 1446.71740723, 1377.78503418,\n",
       "       1347.16748047, 1428.27368164, 1373.25061035, 1476.90991211,\n",
       "       1407.5612793 , 1471.22973633, 1449.36328125, 1448.57312012,\n",
       "       1294.8104248 , 1446.53540039, 1444.33630371, 1432.90490723,\n",
       "       1445.03686523, 1468.66833496, 1453.6673584 , 1452.4864502 ,\n",
       "       1471.71765137, 1385.2286377 ,    0.        ,  230.33004761,\n",
       "         38.56798172,  108.69243622,  146.60340881])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_distances[70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dea507-ad4d-40bc-a0f7-751df0b2eece",
   "metadata": {},
   "source": [
    "### MDS Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2acaaa0b-86fc-48c4-b9c3-34cdacee1c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(n_components=2, metric=True, dissimilarity='precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b761ae48-0334-4068-92dd-db7aee2ea429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dna_pca = mds.fit_transform(new_distances)\n",
    "dna_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e5f52d7-a41d-495a-a385-7e3512eacb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "for i in range(0, num_samples_per_file*len(files), num_samples_per_file):\n",
    "    plt.scatter(*dna_pca[i:i+num_samples_per_file].T)\n",
    "plt.title(\"MDS of Chamfer Distances Between DNA Samples\")\n",
    "plt.scatter(*dna_pca[len(distances):].T)\n",
    "plt.legend(files + [f\"Synthesized ({steps} steps)\"], loc=\"upper center\", bbox_to_anchor=(0.46, -0.1), fancybox=True, ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e00c19-ae16-4c6b-b92f-864d70e6c6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ()",
   "language": "python",
   "name": "lambda-stack"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
